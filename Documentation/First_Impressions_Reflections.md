# REFLECTIONS

## Platform Reflections: Preliminary

### Reddit

I am expecting to come across the most transphobic content in these results. I do not fully know how the Reddit search algorithm functions, but I expect it to prefer high traffic subreddits, such as r/news and r/politics. As a a result, I am predicting that there will be an emphasis on Lia Thomas, the transgender NCAA swimmer who has received mainstream media attention in late March 2022. There are numerous subreddits ran by and for transgender people, but I expect minimal representation within the results owing to lower user numbers.

In contrast to the other platforms, Reddit's content is created by users and has no publishing standards to follow. I expect more of a tendency towards recency than other platforms. I expect the GPT-2 generated text from Reddit to be the most unique and easily recognizable. 

### JSTOR

I am expecting more results to come from medical and health fields than the humanities and social sciences, but expect both to be represented. Owing to the nature of academic publishing, I expect the results to be focus on longer term trends and systems rather than recent events.

I expect the GPT-2 generated text to use more formal, academic language than the results from other platforms. Specifically, I predict substantially higher usage of medical terminology.

### YouTube

In my experience, YouTube search results tend to display a combination of recently uploaded, trending content and older related content with high view numbers. I expect the same to be true for this search, with the former consisting of videos from journalism outlets and users sharing opinions on recent news. I expect the older content to be more diverse, with content created both by transgender people and people with anti-transgender beliefs.

I am expecting the language of the GPT-2 generated text to compare to those generated from CBC and BBC content, with more colloquial language dispersed throughout.


### CBC

I have not read or listened to much CBC content related to transgender topics. I'm not sure what to expect, but I am interested in comparing CBC and BBC. I expect to find results about both transgender athletes and recent bills that have been passed in the United States. 

I am expecting moderately formal language, but radio segments may change this if they appear in great enough numbers.

### BBC

Much like CBC.ca, I do not have much experience with transgender news and content from BBC.co.uk. I chose it as platform owing to the article "We're Being Pressured into sex by some trans women," a heavily disputed piece by Caroline Lowbridge that has been accused of being transphobic and led to numerous protests in the UK. The article has since been removed, but I am curious if this perspective will be reflected in the results.

I am expecting very similar language to CBC.


## Platform Reflections: Post

### Reddit

Reddit was one of the easier platforms to use with GPT-2. Reddit comments are generally much shorter than the articles and videos from other platforms, but a larger amount were used to construct the corpus (5 comments in 50 threads = 250 total). This did not cause any problems, but rather demonstrated the importance of using a large quantity of content.

The Reddit search results were largely what I expected. Almost the entirety of the results were posts from the previous month, with at least half focusing on either Lia Thomas or transgender bathroom and sports bills in the United States. The posts could largely be divided into two categories: expressing disgust towards trans people and expressing disgust towards Republicans. Interestingly, the latter seemed to be the predominant "progressive" political approach, rather than discussing trans people themselves. I also only noticed a handful of comments written by someone openly identifying ad transgender, with the numerous trans support and education subreddits being largely absent in the results. There were also numerous top upvoted comments referencing South Park, an animated adult television show that has multiple episodes about trans people.

The language used in the generated texts is mostly casual, which is unsurprising for Reddit. This includes swear words, abbreviations (such as "wdym" for "what do you mean?"), spelling errors, and creative punctuation and grammar. The texts from Reddit also contain more explicit transphobia than any other platform in this project. I found the reddit texts some of the easier ones to identify, though there are many similarities to Youtube.

### JSTOR 

JSTOR turned out to be one of the most difficult platforms to use with GPT-2. The articles were much longer than results from other platforms. This resulted in the JSTOR text corpus being the largest in size, even though a smaller number of results was used, which is the opposite of Reddit. I believe this is what led to the repetition problems discussed in PARADATA and could have been remedied by increasing the number of articles used. Though this change would likely move the project beyond "First Impressions" and require a reconceptualization.

The JSTOR search results were not strictly medical as I suspected, but rather heavily weighted towards the social sciences. Multiple articles were displayed from the Williams Institute at UCLA that discuss the public opinion of transgender rights in various countries. Multiple articles about transgender students and academics in higher education were displayed as well.

The language used in the generated texts is often formal and academic, as I predicted. While there were not many articles specifically about health and medicine, medical language and discussions could still be found in several of the texts. I found that the JSTOR texts were the easiest to identify.

### YouTube

YouTube was difficult to use with GPT-2 owing to the corpus formatting issues discussed in PARADATA.  This could have largely been avoided If I had made additional use of grepWIN to format the text. Once I fixed these problems, the texts were most often legible and not from only 1-2 videos.

The YouTube results were somewhat varied, but there was more of a recency bias than I expected. Lia Thomas and sports and bathroom bills were once again the most popular topics, with channels from official journalism outlets being the most numerous. I believe this provides more insight into YouTube's algorithm and priorities than it does to the content being posted.

The language used in generated texts is more varied than those from other platforms. I believe this comes from the contrast between the language used by official news channels and that used in videos from "content creators." I found the YouTube texts difficult to identify, with some being easily confused with Reddit and others with CBC and BBC.

### CBC

CBC was one of the easiest platforms to use with GPT-2. I was concerned that combining text articles and transcribed audio would create difficulties, but none arose.

The results from CBC were approximately 60% text and 40% audio. The text results were largely focused on sports and transphobic bills in the United States, with some articles about local trans events in various Canadian cities. Most of the audio results were interviews with either transgender people, or people considered experts by CBC. A large number of the audio results were from a single reporter in Saskatchewan.

Unsurprisingly, the language used in the generated texts is similar to that used in journalism. The language patterns were mostly consistent and the texts required few manual edits. I believe this resulted from the use of a standardized set of procedures for journalists having their work posted to the website. 

### BBC

BBC was one of the easier platforms to use with GPT-2. 

The results from BBC were mostly text, with a few radio clips. While almost every platform displayed numerous results about sports, the BBC results were almost entirely sports. Athletes and regulations both in the United Kingdom and the United States were well represented. There were a small number of articles that were not about either of these two countries, with most of these being about politics or creative endeavours. 

Much like CBC, the language used in the generated texts resembles journalism. Similarly, I did not have to make a large number of edits.


## Platform Reflection Conclusion

When looking at the generated texts from all five platforms together, the largest noticeable trend is a lack of transgender voices. Almost none of the generated texts are written in the first person or from a trans perspective. The search results were largely written about trans people, rather than by trans people, which has clearly informed the generated texts. Transgender people are creating content on most of these platforms, but their articles, videos, and posts are not well represented in the search results. [In her 2014 article](https://doi.org/10.1215/23289252-2815255), Laura Horak studied several trans creators on YouTube, analyzing both who the creators were and what videos they were making. Many of these videos took the form of vlogs, placing the creator in the position of expert in conversation with the viewer. Many video were focused on medical transition, often taking the form of transition timelines. Horak, and other scholars more recently, have noted and studied the existence of not only transgender creators on YouTube, but also trans communities that form around them. So why was none of this reflected in the search results? I suspect the sort of content they describe still exists and is still being created, but the YouTube algorithm in 2022 prioritizes channels from formal media groups over those from individual creators. Further research would be required to confirm this hypothesis.

The topics discussed by these platforms in relation to transgender people can further illustrate how they are represented in media. If someone had no knowledge of trans topics and only read the texts generated in this project, they would probably assume that most transgender people are American and that they are all star athletes. Sports was overwhelmingly the most common topic that appeared in the results, closely followed by anti-transgender bills in the United States. This focus on trans athletes is a relatively modern phenomenon. [In Thomas Ballard's 2016 study](https://ijoc.org/index.php/ijoc/article/view/3461)on the representation of transgenderism in mainstream media, sports are not mentioned once. However, while the topics may have changed, the way in which the media covers them has not. Ballard found four patterns: misnaming and misgendering, misrepresentations of transgender identity, use of the transgender "trickster" trope, and sexualization of the transgender body. All four of these trends are present in _First Impression_'s generated text to varying degrees, with much of the discussion concerning transgender people in sports falling under the "trickster" category. 


## Concluding Reflections 

### GPT-2 in the Digital Humanities

My decision to use GPT-2 instead of a traditional text analysis or visualization tool, such as Voyant, was primarily determined by my intended audience. When I first conceptualized _First Impressions_, my goal was to create an interactive final product that would engage both scholars and anyone outside of academia interested in the topic or methodology. Initial user impressions suggest that this was a success. Site testers exhibited positive reactions, with several sharing nuanced reflections based on their interactions with the texts. 

Using GPT-2 for this topic specifically raises the question: If an AI learned transphobic language and harmful ideas from these platforms, what do humans learn from them? 


### What would I have done differently?

First, I would have formatted my corpora further. As previously mentioned, this caused several problems and forced me to manually edit all of the generated texts to ensure a degree for conformity between platforms. This is knowledge that I will take to any future work with neural networks.

Second, I would have explored the change in platforms over time. Several research questions could emerge from this approach, including:
+ How do platforms change over time?
+ How do the same trends emerge on different platforms?
+ Can neural networks highlight how different platforms influence each other?

Third, I would have become familiar with generic web scrapers, rather than just platform specific tools.

Finally, if possible, I would move the project away from Google Colaboratory to either a personal computer or another virtual machine.

### Final Words

Thank you so much for making it this far! I hope you've enjoyed _First Impressions_. This project was designed as an experiment and involved a lot of risks, but I am happy with the end result. While I made several mistakes, I learned new tools and processes, engaged with new literature, and will take my experiences forward to new Digital Humanities projects in the future.

Stay tuned for my next digital project!
